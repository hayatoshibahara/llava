ğŸŸ© Mon Dec  1 18:08:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |
+-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 5090        Off |   00000000:02:00.0  On |                  N/A |
| 30%   39C    P0             90W /  575W |    1576MiB /  32607MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

ğŸŸ© Python 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]
ğŸŸ© Transformers: 4.57.1
ğŸŸ© ãƒ¢ãƒ‡ãƒ«åã‚’ãƒ‘ã‚¹ã‹ã‚‰æŠ½å‡º result='llava-v1.5-7b'
ğŸŸ© äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ model_path='liuhaotian/llava-v1.5-7b', model_base=None, model_name='llava-v1.5-7b', load_8bit=False, load_4bit=False, device_map='auto', device='cuda', use_flash_attn=False, kwargs={}
ğŸŸ¦ é€šå¸¸ã®LLaVAãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
ğŸŸ¦ Starting new HTTPS connection (1): huggingface.co:443
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/tokenizer_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
ğŸŸ¦ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ tokenizer=LlamaTokenizer(name_or_path='liuhaotian/llava-v1.5-7b', vocab_size=32000, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
) liuhaotian/llava-v1.5-7b
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/model.safetensors.index.json HTTP/1.1" 404 0
ğŸŸ¦ Starting new HTTPS connection (1): huggingface.co:443
ğŸŸ© LlavaLlamaForCausalLMã‚’åˆæœŸåŒ– config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}

ğŸŸ© LlavaLlamaModelã‚’åˆæœŸåŒ– config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}

ğŸŸ© LlavaMetaModelã‚’åˆæœŸåŒ– config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}

ğŸŸ© ãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ãƒ¯ãƒ¼ã‚’æ§‹ç¯‰ vision_tower_cfg=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}
, kwargs={'delay_load': True}
ğŸŸ¦ is_absolute_path_exists=False
ğŸŸ¦ use_s2=False
ğŸŸ© CLIPVisionTowerã‚’åˆæœŸåŒ– vision_tower='openai/clip-vit-large-patch14-336' args=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}
 delay_load=True
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/config.json HTTP/1.1" 200 0
ğŸŸ¦ CLIPVisionConfigã‚’èª­ã¿è¾¼ã‚€ self.cfg_only=CLIPVisionConfig {
  "attention_dropout": 0.0,
  "dropout": 0.0,
  "hidden_act": "quick_gelu",
  "hidden_size": 1024,
  "image_size": 336,
  "initializer_factor": 1.0,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "model_type": "clip_vision_model",
  "num_attention_heads": 16,
  "num_channels": 3,
  "num_hidden_layers": 24,
  "patch_size": 14,
  "projection_dim": 768,
  "transformers_version": "4.57.1"
}

ğŸŸ© ãƒ“ã‚¸ãƒ§ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã‚’æ§‹ç¯‰ config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}
, delay_load=False, kwargs={}
ğŸŸ¦ projector_type='mlp2x_gelu'
ğŸŸ¦ mlp_depth=2
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b HTTP/1.1" 200 3087
ğŸŸ© We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/commits/main HTTP/1.1" 200 1534
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/discussions?p=0 HTTP/1.1" 200 20294
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/commits/refs%2Fpr%2F14 HTTP/1.1" 200 2499
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/refs%2Fpr%2F14/model.safetensors.index.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/66456a4fdc5655d2f39a9d533f80e8ae961a51eb/model.safetensors.index.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/refs%2Fpr%2F14/model.safetensors.index.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/66456a4fdc5655d2f39a9d533f80e8ae961a51eb/model.safetensors.index.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/generation_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/generation_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
ğŸŸ¦ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ model=LlavaLlamaForCausalLM(
  (model): LlavaLlamaModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((4096,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
    (vision_tower): CLIPVisionTower()
    (mm_projector): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) model_path='liuhaotian/llava-v1.5-7b'
ğŸŸ© CLIPVisionTowerã‚’èª­ã¿è¾¼ã¿ device_map='auto'
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/preprocessor_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/preprocessor_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/processor_config.json HTTP/1.1" 404 0
ğŸŸ¦ CLIPImageProcessorã‚’ãƒ­ãƒ¼ãƒ‰ self.image_processor=CLIPImageProcessor {
  "crop_size": {
    "height": 336,
    "width": 336
  },
  "do_center_crop": true,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "CLIPImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "shortest_edge": 336
  }
}

ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/model.safetensors HTTP/1.1" 404 0
ğŸŸ© We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336 HTTP/1.1" 200 4833
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336/commits/main HTTP/1.1" 200 1882
ğŸŸ¦ CLIPVisionModelã‚’ãƒ­ãƒ¼ãƒ‰ self.vision_tower=CLIPVisionModel(
  (vision_model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
      (position_embedding): Embedding(577, 1024)
    )
    (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-23): 24 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
)
ğŸŸ¦ context_len=2048
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336/discussions?p=0 HTTP/1.1" 200 13175
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336/commits/refs%2Fpr%2F20 HTTP/1.1" 200 2847
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/refs%2Fpr%2F20/model.safetensors.index.json HTTP/1.1" 404 0
ğŸŸ© ãƒ¢ãƒ‡ãƒ«åã‚’ãƒ‘ã‚¹ã‹ã‚‰æŠ½å‡º result='llava-v1.5-7b'
ğŸŸ© ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚’å®Ÿè¡Œ args.model_path='liuhaotian/llava-v1.5-7b', args.model_base=None, args.model_name='llava-v1.5-7b', args.query='What are the things I should be cautious about when I visit here?', args.conv_mode=None, args.image_file='https://llava-vl.github.io/static/images/view.jpg', args.sep=',', args.temperature=0, args.top_p=None, args.num_beams=1, args.max_new_tokens=512
ğŸŸ© PyTorchãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆæœŸåŒ–ã‚’ç„¡åŠ¹åŒ–
ğŸŸ© ãƒ¢ãƒ‡ãƒ«åã‚’ãƒ‘ã‚¹ã‹ã‚‰æŠ½å‡º result='llava-v1.5-7b'
ğŸŸ© äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ model_path='liuhaotian/llava-v1.5-7b', model_base=None, model_name='llava-v1.5-7b', load_8bit=False, load_4bit=False, device_map='auto', device='cuda', use_flash_attn=False, kwargs={}
ğŸŸ¦ é€šå¸¸ã®LLaVAãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/refs%2Fpr%2F20/model.safetensors HTTP/1.1" 302 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/tokenizer_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
ğŸŸ¦ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ tokenizer=LlamaTokenizer(name_or_path='liuhaotian/llava-v1.5-7b', vocab_size=32000, model_max_length=2048, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	0: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
) liuhaotian/llava-v1.5-7b
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/model.safetensors.index.json HTTP/1.1" 404 0
ğŸŸ© LlavaLlamaForCausalLMã‚’åˆæœŸåŒ– config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}

ğŸŸ© LlavaLlamaModelã‚’åˆæœŸåŒ– config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}

ğŸŸ© LlavaMetaModelã‚’åˆæœŸåŒ– config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}

ğŸŸ© ãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ãƒ¯ãƒ¼ã‚’æ§‹ç¯‰ vision_tower_cfg=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}
, kwargs={'delay_load': True}
ğŸŸ¦ is_absolute_path_exists=False
ğŸŸ¦ use_s2=False
ğŸŸ© CLIPVisionTowerã‚’åˆæœŸåŒ– vision_tower='openai/clip-vit-large-patch14-336' args=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}
 delay_load=True
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b HTTP/1.1" 200 3087
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/config.json HTTP/1.1" 200 0
ğŸŸ¦ CLIPVisionConfigã‚’èª­ã¿è¾¼ã‚€ self.cfg_only=CLIPVisionConfig {
  "attention_dropout": 0.0,
  "dropout": 0.0,
  "hidden_act": "quick_gelu",
  "hidden_size": 1024,
  "image_size": 336,
  "initializer_factor": 1.0,
  "initializer_range": 0.02,
  "intermediate_size": 4096,
  "layer_norm_eps": 1e-05,
  "model_type": "clip_vision_model",
  "num_attention_heads": 16,
  "num_channels": 3,
  "num_hidden_layers": 24,
  "patch_size": 14,
  "projection_dim": 768,
  "transformers_version": "4.57.1"
}

ğŸŸ© ãƒ“ã‚¸ãƒ§ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã‚’æ§‹ç¯‰ config=LlavaConfig {
  "architectures": [
    "LlavaLlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "dtype": "float16",
  "eos_token_id": 2,
  "freeze_mm_mlp_adapter": false,
  "freeze_mm_vision_resampler": false,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "image_aspect_ratio": "pad",
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_length": 4096,
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "mm_hidden_size": 1024,
  "mm_projector_type": "mlp2x_gelu",
  "mm_resampler_type": null,
  "mm_use_im_patch_token": false,
  "mm_use_im_start_end": false,
  "mm_vision_select_feature": "patch",
  "mm_vision_select_layer": -2,
  "mm_vision_tower": "openai/clip-vit-large-patch14-336",
  "model_type": "llava_llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pad_token_id": 0,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "tune_mm_mlp_adapter": false,
  "tune_mm_vision_resampler": false,
  "unfreeze_mm_vision_tower": false,
  "use_cache": true,
  "use_mm_proj": true,
  "vocab_size": 32000
}
, delay_load=False, kwargs={}
ğŸŸ¦ projector_type='mlp2x_gelu'
ğŸŸ¦ mlp_depth=2
ğŸŸ© We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/commits/main HTTP/1.1" 200 1534
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/discussions?p=0 HTTP/1.1" 200 20294
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/liuhaotian/llava-v1.5-7b/commits/refs%2Fpr%2F14 HTTP/1.1" 200 2499
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/refs%2Fpr%2F14/model.safetensors.index.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/66456a4fdc5655d2f39a9d533f80e8ae961a51eb/model.safetensors.index.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/refs%2Fpr%2F14/model.safetensors.index.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/66456a4fdc5655d2f39a9d533f80e8ae961a51eb/model.safetensors.index.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/generation_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/liuhaotian/llava-v1.5-7b/4481d270cc22fd5c4d1bb5df129622006ccd9234/generation_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /liuhaotian/llava-v1.5-7b/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
ğŸŸ¦ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ model=LlavaLlamaForCausalLM(
  (model): LlavaLlamaModel(
    (embed_tokens): Embedding(32000, 4096, padding_idx=0)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((4096,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
    (vision_tower): CLIPVisionTower()
    (mm_projector): Sequential(
      (0): Linear(in_features=1024, out_features=4096, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
) model_path='liuhaotian/llava-v1.5-7b'
ğŸŸ© CLIPVisionTowerã‚’èª­ã¿è¾¼ã¿ device_map='auto'
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/preprocessor_config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/preprocessor_config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/processor_config.json HTTP/1.1" 404 0
ğŸŸ¦ CLIPImageProcessorã‚’ãƒ­ãƒ¼ãƒ‰ self.image_processor=CLIPImageProcessor {
  "crop_size": {
    "height": 336,
    "width": 336
  },
  "do_center_crop": true,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "CLIPImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "shortest_edge": 336
  }
}

ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/config.json HTTP/1.1" 307 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /api/resolve-cache/models/openai/clip-vit-large-patch14-336/ce19dc912ca5cd21c8a653c79e251e808ccabcd1/config.json HTTP/1.1" 200 0
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/main/model.safetensors HTTP/1.1" 404 0
ğŸŸ© We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336 HTTP/1.1" 200 4833
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336/commits/main HTTP/1.1" 200 1882
ğŸŸ¦ CLIPVisionModelã‚’ãƒ­ãƒ¼ãƒ‰ self.vision_tower=CLIPVisionModel(
  (vision_model): CLIPVisionTransformer(
    (embeddings): CLIPVisionEmbeddings(
      (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)
      (position_embedding): Embedding(577, 1024)
    )
    (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (encoder): CLIPEncoder(
      (layers): ModuleList(
        (0-23): 24 x CLIPEncoderLayer(
          (self_attn): CLIPAttention(
            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
          )
          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (mlp): CLIPMLP(
            (activation_fn): QuickGELUActivation()
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          )
          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
)
ğŸŸ¦ context_len=2048
ğŸŸ¦ ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ã‚’æ±ºå®š args.conv_mode='llava_v1'
ğŸŸ© ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ  role='USER', message='<image>\nWhat are the things I should be cautious about when I visit here?'
ğŸŸ© ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ  role='ASSISTANT', message=None
ğŸŸ© ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰é–‹å§‹ messages=[['USER', '<image>\nWhat are the things I should be cautious about when I visit here?'], ['ASSISTANT', None]], self.sep_style=<SeparatorStyle.TWO: 2>, self.version='v1'
ğŸŸ© ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰å®Œäº† ret="A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: <image>\nWhat are the things I should be cautious about when I visit here? ASSISTANT:"
ğŸŸ© ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾— out=['https://llava-vl.github.io/static/images/view.jpg']
ğŸŸ¦ Starting new HTTPS connection (1): llava-vl.github.io:443
ğŸŸ¦ https://llava-vl.github.io:443 "GET /static/images/view.jpg HTTP/1.1" 200 95499
ğŸŸ© PILç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰ image_file='https://llava-vl.github.io/static/images/view.jpg', image.size=(1000, 667), image.mode='RGB'
ğŸŸ¦ ç”»åƒã‚µã‚¤ã‚ºã‚’å–å¾— image_sizes=[(1000, 667)]
ğŸŸ© ç”»åƒã‚’å‰å‡¦ç† len(images)=1, model_cfg.image_aspect_ratio='pad'
ğŸŸ© PILç”»åƒã‚’æ­£æ–¹å½¢ã«æ‹¡å¼µ pil_img.size=(1000, 667), background_color=(122, 116, 104)
ğŸŸ¦ å‰å‡¦ç†ã•ã‚ŒãŸç”»åƒãƒ†ãƒ³ã‚½ãƒ« new_images.shape=torch.Size([1, 3, 336, 336]), new_images.dtype=torch.float32
ğŸŸ© ç”»åƒãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ– prompt="A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: <image>\nWhat are the things I should be cautious about when I visit here? ASSISTANT:", image_token_index=-200, return_tensors='pt'
ğŸŸ¦ prompt_chunks=[[1, 319, 13563, 1546, 263, 12758, 5199, 322, 385, 23116, 21082, 20255, 29889, 450, 20255, 4076, 8444, 29892, 13173, 29892, 322, 1248, 568, 6089, 304, 278, 5199, 29915, 29879, 5155, 29889, 3148, 1001, 29901, 29871], [1, 29871, 13, 5618, 526, 278, 2712, 306, 881, 367, 274, 1300, 2738, 1048, 746, 306, 6493, 1244, 29973, 319, 1799, 9047, 13566, 29901]]
ğŸŸ© ç”»åƒãƒˆãƒ¼ã‚¯ãƒ³åŒ–çµæœã‚’ãƒ†ãƒ³ã‚½ãƒ«ã§è¿”ã™ result.shape=torch.Size([59]), result.dtype=torch.int64
ğŸŸ¦ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ– tensor([[    1,   319, 13563,  1546,   263, 12758,  5199,   322,   385, 23116,
         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,
           322,  1248,   568,  6089,   304,   278,  5199, 29915, 29879,  5155,
         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,   526,
           278,  2712,   306,   881,   367,   274,  1300,  2738,  1048,   746,
           306,  6493,  1244, 29973,   319,  1799,  9047, 13566, 29901]],
       device='cuda:0')
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆé–‹å§‹ inputs.shape=torch.Size([1, 59]), images.shape=torch.Size([1, 3, 336, 336]), image_sizes=[(1000, 667)], kwargs={'do_sample': False, 'temperature': 0, 'top_p': None, 'num_beams': 1, 'max_new_tokens': 512, 'use_cache': True}
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 59]), position_ids.shape if position_ids is not None else None=None, attention_mask.shape if attention_mask is not None else None=None, past_key_values=None, labels.shape if labels is not None else None=None, type(images)=<class 'torch.Tensor'>, image_sizes=[(1000, 667)]
ğŸŸ¦ å˜ä¸€ã®ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ torch.Size([1, 3, 336, 336])
ğŸŸ© ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ images.shape=torch.Size([1, 3, 336, 336])
ğŸŸ© CLIPVisionTowerã®é †ä¼æ¬ type(images)=<class 'torch.Tensor'>
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336/discussions?p=0 HTTP/1.1" 200 13175
ğŸŸ© CLIPVisionTowerã®ç‰¹å¾´é‡é¸æŠ type(image_forward_outs)=<class 'transformers.modeling_outputs.BaseModelOutputWithPooling'>
ğŸŸ¦ é¸æŠã•ã‚ŒãŸå±¤ã®éš ã‚ŒçŠ¶æ…‹ image_features.shape=torch.Size([1, 577, 1024])
ğŸŸ¦ ãƒ‘ãƒƒãƒç‰¹å¾´é‡ã®ã¿é¸æŠ image_features.shape=torch.Size([1, 576, 1024])
ğŸŸ¦ ãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ãƒ¯ãƒ¼ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ image_features.shape=torch.Size([1, 576, 1024])
ğŸŸ¦ https://huggingface.co:443 "GET /api/models/openai/clip-vit-large-patch14-336/commits/refs%2Fpr%2F20 HTTP/1.1" 200 2847
ğŸŸ¦ ãƒ“ã‚¸ãƒ§ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã§å¤‰æ› image_features.shape=torch.Size([1, 576, 4096])
ğŸŸ¦ attention_mask=tensor([[True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True, True,
         True, True, True, True, True, True, True, True, True, True, True]],
       device='cuda:0')
ğŸŸ¦ å‡¦ç†ä¸­ã®ãƒãƒƒãƒ batch_idx=0, cur_input_ids.shape=torch.Size([59])
ğŸŸ¦ batch_idx=0, num_images=tensor(1, device='cuda:0')
ğŸŸ¦ batch_idx=0, image_token_indices=[-1, 35, 59]
ğŸŸ¦ cur_input_embeds.shape=torch.Size([58, 4096])
ğŸŸ¦ len(cur_input_embeds_no_im)=2
ğŸŸ¦ tokenizer_model_max_length=None
ğŸŸ¦ max_len=634
ğŸŸ¦ batch_size=1
ğŸŸ¦ i=0, cur_len=634
ğŸŸ¦ å³ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° i=0, cur_len=634
ğŸŸ¦ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å¾Œã®å…¥åŠ›åŸ‹ã‚è¾¼ã¿ new_input_embeds.shape=torch.Size([1, 634, 4096])
ğŸŸ¦ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™å®Œäº† new_input_embeds.shape=torch.Size([1, 634, 4096]), position_ids=None, attention_mask=None, past_key_values=None, new_labels=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 0]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/refs%2Fpr%2F20/model.safetensors.index.json HTTP/1.1" 404 0
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 1]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 635]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 2]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 636]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 3]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 637]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 4]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 638]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 5]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 639]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 6]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 640]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 7]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 641]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 8]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 642]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 9]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 643]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ¦ https://huggingface.co:443 "HEAD /openai/clip-vit-large-patch14-336/resolve/refs%2Fpr%2F20/model.safetensors HTTP/1.1" 302 0
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 10]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 644]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 11]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 645]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 12]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 646]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 13]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 647]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 14]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 648]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 15]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 649]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 16]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 650]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 17]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 651]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 18]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 652]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 19]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 653]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 20]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 654]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 21]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 655]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 22]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 656]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 23]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 657]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 24]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 658]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 25]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 659]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 26]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 660]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 27]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 661]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 28]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 662]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 29]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 663]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 30]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 664]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 31]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 665]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 32]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 666]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 33]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 667]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 34]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 668]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 35]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 669]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 36]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 670]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 37]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 671]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 38]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 672]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 39]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 673]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 40]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 674]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 41]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 675]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 42]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 676]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 43]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 677]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 44]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 678]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 45]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 679]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 46]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 680]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 47]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 681]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 48]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 682]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 49]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 683]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 50]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 684]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 51]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 685]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 52]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 686]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 53]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 687]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 54]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 688]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 55]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 689]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 56]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 690]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 57]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 691]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 58]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 692]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 59]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 693]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 60]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 694]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 61]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 695]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 62]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 696]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 63]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 697]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 64]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 698]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 65]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 699]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 66]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 700]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 67]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 701]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 68]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 702]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 69]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 703]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 70]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 704]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 71]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 705]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 72]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 706]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 73]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 707]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 74]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 708]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 75]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 709]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 76]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 710]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 77]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 711]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 78]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 712]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 79]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 713]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 80]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 714]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 81]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 715]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 82]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 716]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 83]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 717]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 84]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 718]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 85]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 719]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 86]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 720]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 87]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 721]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 88]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 722]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 89]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 723]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 90]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 724]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 91]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 725]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 92]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 726]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 93]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 727]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 94]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 728]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 95]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 729]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 96]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 730]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 97]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 731]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 98]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 732]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 99]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 733]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 100]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 734]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 101]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 735]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 102]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 736]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 103]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 737]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 104]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 738]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 105]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 739]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 106]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 740]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 107]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 741]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 108]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 742]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 109]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 743]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 110]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 744]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 111]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 745]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 112]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 746]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 113]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 747]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 114]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 748]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 115]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 749]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 116]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 750]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 117]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 751]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 118]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 752]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 119]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 753]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 120]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 754]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 121]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 755]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 122]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 756]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 123]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 757]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 124]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 758]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 125]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 759]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 126]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 760]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 127]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 761]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 128]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 762]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 129]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 763]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 130]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 764]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 131]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 765]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 132]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 766]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 133]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 767]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 134]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 768]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 135]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 769]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 136]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 770]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 137]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 771]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 138]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 772]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 139]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 773]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 140]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 774]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 141]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 775]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 142]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 776]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 143]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 777]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 144]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 778]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 145]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 779]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 146]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 780]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 147]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 781]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 148]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 782]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 149]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 783]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 150]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 784]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 151]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 785]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 152]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 786]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 153]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 787]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 154]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 788]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 155]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 789]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 156]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 790]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 157]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 791]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 158]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 792]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 159]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 793]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 160]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 794]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 161]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 795]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 162]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 796]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ© ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç”¨ã«å…¥åŠ›ã‚’æ•´å½¢ input_ids.shape=torch.Size([1, 163]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), inputs_embeds.shape if inputs_embeds is not None else None=torch.Size([1, 634, 4096]), images.shape if images is not None else None=None, image_sizes=None, kwargs.keys()=dict_keys(['position_ids', 'attention_mask', 'use_cache', 'cache_position'])
ğŸŸ¦ æ•´å½¢å¾Œã®å…¥åŠ› inputs.keys()=dict_keys(['cache_position', 'past_key_values', 'input_ids', 'inputs_embeds', 'position_ids', 'attention_mask', 'use_cache'])
ğŸŸ© ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã®æº–å‚™ input_ids.shape=torch.Size([1, 1]), position_ids.shape if position_ids is not None else None=torch.Size([1, 1]), attention_mask.shape if attention_mask is not None else None=torch.Size([1, 797]), past_key_values=DynamicCache(layers=[DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer, DynamicLayer]), labels.shape if labels is not None else None=None, type(images)=<class 'NoneType'>, image_sizes=None
ğŸŸ¦ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆçµæœ result=tensor([[ 1932,  6493,   292,   445,  4423, 29892,   607,  5680,   263,  9307,
         23771,   975,   263,  2919,  3573,   310,  4094, 29892,   727,   526,
           263,  2846,  2712,   304,   367,   274,  1300,  2738,  1048, 29889,
          3824, 29892,   367,  3458,  1319,   310,   278, 14826,  5855, 29892,
           408,   278,  9307,  1122,   367, 15201,   491,  4549,  8805, 29879,
           470, 14280, 29879, 29892,   607,  1033,  1207,   372, 25110,   304,
          6686,   373, 29889,  6440, 29892,   367,  9543,   310,   278,  4094,
         10809,   322,   738,  7037,   447, 29920,  3163, 29892,  1316,   408,
          1014,  1050,  3192, 23150,   470,   316,  1182,   275, 29892,   393,
          1033, 18593,   263, 12045,   304,   596, 15332, 29889, 19814, 29892,
           367,   274,  1300,  2738,   310,   278, 10122,   310,  8775, 19264,
           297,   278,  4038, 29892,   408,   727,  1795,   367, 17952,   470,
           916, 15006,   393,  1033, 18593,   263, 28469,   470, 29543,   749,
         29889,  9788, 29892,   367,  3390,  1319,   310,   278,  5177,   322,
           916, 26824, 29892,   322,  1101,   738,  8059,  6865,   470,  1410,
         10652,  1475,   304,  9801,   263,  9109,   322, 13389,   519,  7271,
           363, 14332, 29889,     2]], device='cuda:0')
ğŸŸ© ç”Ÿæˆçµæœã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰å®Œäº† outputs='When visiting this location, which features a pier extending over a large body of water, there are a few things to be cautious about. First, be mindful of the weather conditions, as the pier may be affected by strong winds or storms, which could make it unsafe to walk on. Second, be aware of the water depth and any potential hazards, such as submerged rocks or debris, that could pose a risk to your safety. Additionally, be cautious of the presence of wildlife in the area, as there might be birds or other animals that could pose a threat or disturbance. Finally, be respectful of the environment and other visitors, and follow any posted rules or guidelines to ensure a safe and enjoyable experience for everyone.'
